{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees - Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply read the dataset into a list of list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Rainy', 'Hot', 'High', 'False', 'No'],\n",
       " ['Rainy', 'Hot', 'High', 'True', 'No'],\n",
       " ['Overcast', 'Hot', 'High', 'False', 'Yes'],\n",
       " ['Sunny', 'Mild', 'High', 'False', 'Yes'],\n",
       " ['Sunny', 'Cool', 'Normal', 'False', 'Yes'],\n",
       " ['Sunny', 'Cool', 'High', 'True', 'No'],\n",
       " ['Overcast', 'Cool', 'Normal', 'True', 'Yes'],\n",
       " ['Rainy', 'Mild', 'High', 'False', 'No'],\n",
       " ['Rainy', 'Cool', 'Normal', 'False', 'Yes'],\n",
       " ['Sunny', 'Mild', 'Normal', 'False', 'Yes'],\n",
       " ['Rainy', 'Mild', 'Normal', 'True', 'Yes'],\n",
       " ['Overcast', 'Mild', 'High', 'True', 'Yes'],\n",
       " ['Overcast', 'Hot', 'Normal', 'False', 'Yes'],\n",
       " ['Sunny', 'Mild', 'High', 'True', 'No']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('playgolf.csv') as f:\n",
    "    data = f.readlines()\n",
    "data = [x.strip() for x in data]\n",
    "data2 = []\n",
    "for line in data:\n",
    "    line = [word.strip() for word in line.split(',')]\n",
    "    data2.append(line)\n",
    "data = data2\n",
    "header = ['Outlook', 'Temp', 'Humidity', 'Windy', 'Play Golf']\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entropy \n",
    "\n",
    "The below function uses the entropy formual too calculate the the entropy of given attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9709505944546686"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def entropy(attributeIndex, classifierIndex, inputData, targetAttr):\n",
    "    \n",
    "    #Dictionary that geathers all the different answers for the classifier\n",
    "    answers = {}\n",
    "    totalAnswerCount = 0\n",
    "    \n",
    "    #Go thorugh the data add new answers and how many times they appear to the dictionary\n",
    "    for row in inputData:\n",
    "        if row[attributeIndex] == targetAttr:\n",
    "            totalAnswerCount += 1\n",
    "            if row[classifierIndex] in answers:\n",
    "                answers[row[classifierIndex]] += 1\n",
    "            else:\n",
    "                answers[row[classifierIndex]] = 1\n",
    "    \n",
    "    result = 0\n",
    "    \n",
    "    #Compute the entropy for the answers in the dictionary\n",
    "    for key, answer in answers.items():\n",
    "        result += -((answer/totalAnswerCount)*math.log((answer/totalAnswerCount), 2))\n",
    "    return result\n",
    "    \n",
    "attributeIndex = header.index('Outlook')\n",
    "classifierIndex = header.index('Play Golf')\n",
    "entropy(attributeIndex, classifierIndex, data, \"Sunny\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information gain\n",
    "\n",
    "The below function uses the information gain formula too compute the information gain of a given attribute set, using the entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6935361388961918"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def infoGain(attributeIndex, classifierIndex, inputData):\n",
    "    \n",
    "    #Geather the values for each row item and how often it appears\n",
    "    values = {}\n",
    "    totalSizeOfSet = 0\n",
    "    for row in inputData:\n",
    "        totalSizeOfSet += 1\n",
    "        if row[attributeIndex] in values:\n",
    "            values[row[attributeIndex]] += 1\n",
    "        else:\n",
    "            values[row[attributeIndex]] = 1\n",
    "            \n",
    "    #Compute the actual information gain here\n",
    "    result = 0\n",
    "    for key, value in values.items():\n",
    "        result += (value/totalSizeOfSet)* entropy(attributeIndex, classifierIndex, inputData, key)\n",
    "    return result\n",
    "\n",
    "attributeIndex = header.index('Outlook')\n",
    "classifierIndex = header.index('Play Golf')\n",
    "infoGain(attributeIndex, classifierIndex, data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitter\n",
    "\n",
    "In the below function we loop through all the attributes and use the information gain to choose what attribute to split on. Then we return the different items of the chosen attribute and the index of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitter(data, head, classifier):\n",
    "    \n",
    "    # The attribute is assigned in this varible\n",
    "    lowestAttribute = None\n",
    "    # The attribute information gain value is assigned to this varible\n",
    "    lowestAttributeVal = 1\n",
    "    # The index of the lowest attribute\n",
    "    attributeIndex = 0\n",
    "    \n",
    "    for currentAttributeIndex, attribute in enumerate(head):\n",
    "        #We don't split on the classifier\n",
    "        if attribute == classifier:\n",
    "            continue\n",
    "        #Compute the information gain of curent attribute\n",
    "        attributeInfoGain = infoGain(currentAttributeIndex, classifierIndex, data)\n",
    "        # If the information of current attribute is the lowest, we assign relevant values\n",
    "        if attributeInfoGain <lowestAttributeVal:\n",
    "            attributeIndex = currentAttributeIndex\n",
    "            lowestAttributeVal = attributeInfoGain\n",
    "            lowestAttribute = attribute\n",
    "            \n",
    "    # The items in the attribute, we return a set of them (one of each)\n",
    "    splitReturns = [line[attributeIndex] for line in data]\n",
    "    return (attributeIndex,set(splitReturns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split\n",
    "\n",
    "The below split function ueses the previous functions and recursively splits until the dataset is pure. \n",
    "\n",
    "The other two functions are small helper functions used in split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Pure Subset ---------------------------------\n",
      "\n",
      " ----- Outlook ----- Temp ----- Humidity ----- Windy ----- Play Golf ----- \n",
      "       Sunny         Cool          Normal        False         Yes           \n",
      "       Overcast      Cool          Normal        True          Yes           \n",
      "       Rainy         Cool          Normal        False         Yes           \n",
      "       Sunny         Mild          Normal        False         Yes           \n",
      "       Rainy         Mild          Normal        True          Yes           \n",
      "       Overcast      Hot           Normal        False         Yes           \n",
      "\n",
      "\n",
      "\n",
      "---------------------------- Pure Subset ---------------------------------\n",
      "\n",
      " ----- Outlook ----- Temp ----- Humidity ----- Windy ----- Play Golf ----- \n",
      "       Overcast      Hot           High          False         Yes           \n",
      "       Overcast      Mild          High          True          Yes           \n",
      "\n",
      "\n",
      "\n",
      "---------------------------- Pure Subset ---------------------------------\n",
      "\n",
      " ----- Outlook ----- Temp ----- Humidity ----- Windy ----- Play Golf ----- \n",
      "       Rainy         Hot           High          False         No            \n",
      "       Rainy         Hot           High          True          No            \n",
      "       Rainy         Mild          High          False         No            \n",
      "\n",
      "\n",
      "\n",
      "---------------------------- Pure Subset ---------------------------------\n",
      "\n",
      " ----- Outlook ----- Temp ----- Humidity ----- Windy ----- Play Golf ----- \n",
      "       Sunny         Mild          High          False         Yes           \n",
      "\n",
      "\n",
      "\n",
      "---------------------------- Pure Subset ---------------------------------\n",
      "\n",
      " ----- Outlook ----- Temp ----- Humidity ----- Windy ----- Play Golf ----- \n",
      "       Sunny         Cool          High          True          No            \n",
      "       Sunny         Mild          High          True          No            \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Determines if a subset is pure subset\n",
    "def isPure(subset, classifierIndex):\n",
    "    currentValue = None\n",
    "    for line in subset:\n",
    "        if currentValue is None:\n",
    "            currentValue = line[classifierIndex]\n",
    "        else:\n",
    "            if line[classifierIndex] != currentValue:\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "# Just prints the subset in a better way\n",
    "def printData(head, subset):\n",
    "    print(\"---------------------------- Pure Subset ---------------------------------\" )\n",
    "    print()\n",
    "    for attribute in head:\n",
    "        print(\" ----- \", end='')\n",
    "        print(attribute, end='')\n",
    "    print(\" ----- \")\n",
    "    for line in subset:\n",
    "        print(\"       \", end='')\n",
    "        for element in line:\n",
    "            print(element, end='')\n",
    "            print(((14-len(element))*\" \"), end='')\n",
    "        print()\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "        \n",
    "        \n",
    "\n",
    "def split(data, head, classifier):\n",
    "    \n",
    "    #Call the splitter function from above\n",
    "    splitterOut = splitter(data, head, classifier)\n",
    "    classifierIndex = head.index(classifier)\n",
    "    for value in splitterOut[1]:\n",
    "        # Make a subset with relevant values\n",
    "        subset = [line for line in data if line[splitterOut[0]] == value]\n",
    "        #Print it if it is pure if not call split again with the subset as datab\n",
    "        if  isPure(subset, classifierIndex):\n",
    "            printData(head, subset)\n",
    "            \n",
    "        else: \n",
    "            split(subset, head, classifier)\n",
    "            \n",
    "            \n",
    "split(list(data), list(header), 'Play Golf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Will John play golf?\n",
    "\n",
    "In the function below we can send in the paramters for the relevant attributes and determine if John will play golf or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes\n"
     ]
    }
   ],
   "source": [
    "result = None\n",
    "def splitAndDefine(attributes, data, head, classifier):\n",
    "    global result\n",
    "    #Call the splitter function from above\n",
    "    splitterOut = splitter(data, head, classifier)\n",
    "    classifierIndex = head.index(classifier)\n",
    "    for value in splitterOut[1]:\n",
    "        # Make a subset with relevant values\n",
    "        subset = [line for line in data if line[splitterOut[0]] == value]\n",
    "        #Print it if it is pure if not call split again with the subset as datab\n",
    "        if  isPure(subset, classifierIndex):\n",
    "            for row in subset:\n",
    "                if set(attributes).issubset(set(row)):\n",
    "                    result = row[classifierIndex]\n",
    "            \n",
    "        else: \n",
    "            splitAndDefine(attributes, subset, head, classifier)\n",
    "\n",
    "\n",
    "def willPlayGolf(Outlook, Temp, Humidity, Windy, data, head, classifier):\n",
    "    splitAndDefine((Outlook, Temp, Humidity, Windy), data, head, classifier)\n",
    "\n",
    "\n",
    "willPlayGolf('Sunny', 'Cool', 'Normal', 'False', data, header, 'Play Golf')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-learn and random forest classifier\n",
    "\n",
    "In this example we will use dataset and the random forest classifer from Scikit-learn.\n",
    "Example from: Chris Albon: https://github.com/chrisalbon/notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                5.1               3.5                1.4               0.2\n",
       "1                4.9               3.0                1.4               0.2\n",
       "2                4.7               3.2                1.3               0.2\n",
       "3                4.6               3.1                1.5               0.2\n",
       "4                5.0               3.6                1.4               0.2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Loading data for the training dataset\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>species</th>\n",
       "      <th>is_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "  species  is_train  \n",
       "0  setosa      True  \n",
       "1  setosa     False  \n",
       "2  setosa      True  \n",
       "3  setosa     False  \n",
       "4  setosa      True  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making a new column with the species names, which is what we are going to try to predict\n",
    "df['species'] = pd.Categorical.from_codes(iris.target, iris.target_names)\n",
    "df.head()\n",
    "\n",
    "# Adding another column to randomly assingn some columns to be a part of the training data and others not\n",
    "df['is_train'] = np.random.uniform(0, 1, len(df)) <= .75\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in the training data: 106\n",
      "Number of observations in the test data: 44\n"
     ]
    }
   ],
   "source": [
    "#We crate two data frames, one is for the training data and the other one for testing data\n",
    "train, test = df[df['is_train']==True], df[df['is_train']==False]\n",
    "\n",
    "print('Number of observations in the training data:', len(train))\n",
    "print('Number of observations in the test data:',len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We convert each species name into a digit so we can use it in the classifier\n",
    "y = pd.factorize(train['species'])[0]\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=2,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here we make the classifer and train it with the training data\n",
    "clf = RandomForestClassifier(n_jobs=2, random_state=0)\n",
    "features = df.columns[:4]\n",
    "clf.fit(train[features], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'setosa' 'setosa' 'setosa' 'setosa']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    setosa\n",
       "3    setosa\n",
       "5    setosa\n",
       "6    setosa\n",
       "7    setosa\n",
       "Name: species, dtype: category\n",
       "Categories (3, object): [setosa, versicolor, virginica]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we use the trained classifer to classify the test data which the classifer has never seen before\n",
    "clf.predict(test[features])\n",
    "\n",
    "preds = iris.target_names[clf.predict(test[features])]\n",
    "print(preds[0:5])\n",
    "test['species'].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
